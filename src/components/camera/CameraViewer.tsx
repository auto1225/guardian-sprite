import { Camera, RefreshCw, Download, Video, Play, Volume2, VolumeX, Circle, Square, Mic, MicOff } from "lucide-react";
import { useState, useRef, useEffect, useCallback } from "react";

interface CameraViewerProps {
  isStreaming: boolean;
  isConnecting: boolean;
  isConnected: boolean;
  remoteStream: MediaStream | null;
  error: string | null;
  onRetry: () => void;
  onCapture: () => void;
}

const CameraViewer = ({
  isStreaming,
  isConnecting,
  isConnected,
  remoteStream,
  error,
  onRetry,
  onCapture,
}: CameraViewerProps) => {
  const videoRef = useRef<HTMLVideoElement>(null);
  const [isVideoPlaying, setIsVideoPlaying] = useState(false);
  const [isMuted, setIsMuted] = useState(true);
  const [isRecording, setIsRecording] = useState(false);
  const [recordingDuration, setRecordingDuration] = useState(0);
  const playRetryTimerRef = useRef<NodeJS.Timeout | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const recordedChunksRef = useRef<Blob[]>([]);
  const recordingTimerRef = useRef<NodeJS.Timeout | null>(null);

  // ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •í•œ ìŒì†Œê±° ìƒíƒœ ì¶”ì 
  const userMutePreferenceRef = useRef(true);
  
  // ì˜¤ë””ì˜¤ ë ˆë²¨ ì‹œê°í™”
  const [audioLevel, setAudioLevel] = useState(0);
  const [hasAudioTrack, setHasAudioTrack] = useState(false);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const audioAnimFrameRef = useRef<number | null>(null);

  // ì˜¤ë””ì˜¤ ë ˆë²¨ ëª¨ë‹ˆí„°ë§
  useEffect(() => {
    if (!remoteStream) {
      setAudioLevel(0);
      setHasAudioTrack(false);
      return;
    }

    const audioTracks = remoteStream.getAudioTracks();
    setHasAudioTrack(audioTracks.length > 0);
    if (audioTracks.length === 0) return;

    try {
      const ctx = new AudioContext();
      // ëª¨ë°”ì¼ì—ì„œ suspended ìƒíƒœì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ resume
      if (ctx.state === 'suspended') {
        ctx.resume().catch(() => {});
      }
      console.log("[CameraViewer] ğŸ”Š AudioContext state:", ctx.state, "Audio tracks:", audioTracks.length);
      
      const source = ctx.createMediaStreamSource(remoteStream);
      const analyser = ctx.createAnalyser();
      analyser.fftSize = 256;
      analyser.smoothingTimeConstant = 0.3;
      source.connect(analyser);

      audioContextRef.current = ctx;
      analyserRef.current = analyser;

      // í™”ë©´ í„°ì¹˜ ì‹œ AudioContext resume (ëª¨ë°”ì¼ ì •ì±… ëŒ€ì‘)
      const resumeOnInteraction = () => {
        if (audioContextRef.current?.state === 'suspended') {
          audioContextRef.current.resume().then(() => {
            console.log("[CameraViewer] ğŸ”Š AudioContext resumed after interaction");
          }).catch(() => {});
        }
      };
      document.addEventListener('touchstart', resumeOnInteraction, { once: true });
      document.addEventListener('click', resumeOnInteraction, { once: true });

      const dataArray = new Uint8Array(analyser.frequencyBinCount);
      const tick = () => {
        analyser.getByteFrequencyData(dataArray);
        let sum = 0;
        for (let i = 0; i < dataArray.length; i++) sum += dataArray[i];
        const avg = sum / dataArray.length / 255;
        setAudioLevel(avg);
        audioAnimFrameRef.current = requestAnimationFrame(tick);
      };
      tick();
    } catch (e) {
      console.warn("[CameraViewer] AudioContext error:", e);
    }

    return () => {
      if (audioAnimFrameRef.current) cancelAnimationFrame(audioAnimFrameRef.current);
      if (audioContextRef.current) {
        audioContextRef.current.close().catch(() => {});
        audioContextRef.current = null;
      }
      analyserRef.current = null;
    };
  }, [remoteStream]);

  // ì•ˆì „í•œ ì¬ìƒ ì‹œë„ - ì—¬ëŸ¬ ë²ˆ ë°˜ë³µ ì‹œë„
  const attemptPlay = useCallback(async (retryCount = 0) => {
    const video = videoRef.current;
    if (!video || !video.srcObject) return;

    try {
      // ì²« ì¬ìƒ ì‹œì—ë§Œ muted ê°•ì œ, ì´í›„ì—ëŠ” ì‚¬ìš©ì ì„¤ì • ìœ ì§€
      if (!isVideoPlaying) {
        video.muted = true; // ëª¨ë°”ì¼ì—ì„œ mutedì—¬ì•¼ autoplay ê°€ëŠ¥
      } else {
        video.muted = userMutePreferenceRef.current;
      }
      await video.play();
      console.log("[CameraViewer] âœ… Play succeeded (attempt:", retryCount + 1, ")");
      setIsVideoPlaying(true);
    } catch (err) {
      console.warn("[CameraViewer] âš ï¸ Play failed (attempt:", retryCount + 1, "):", err);
      setIsVideoPlaying(false);
      
      // ìµœëŒ€ 5íšŒê¹Œì§€ 500ms ê°„ê²©ìœ¼ë¡œ ì¬ì‹œë„
      if (retryCount < 5) {
        playRetryTimerRef.current = setTimeout(() => {
          attemptPlay(retryCount + 1);
        }, 500);
      }
    }
  }, [isVideoPlaying]);

  // remoteStreamì´ ë³€ê²½ë˜ë©´ ë¹„ë””ì˜¤ì— ì—°ê²°
  useEffect(() => {
    const video = videoRef.current;
    if (!video || !remoteStream) return;

    console.log("[CameraViewer] ğŸ“¹ Setting video srcObject:", {
      streamId: remoteStream.id,
      active: remoteStream.active,
      trackCount: remoteStream.getTracks().length,
    });

    // ì´ì „ íƒ€ì´ë¨¸ ì •ë¦¬
    if (playRetryTimerRef.current) {
      clearTimeout(playRetryTimerRef.current);
      playRetryTimerRef.current = null;
    }

    video.muted = userMutePreferenceRef.current;
    video.playsInline = true;
    video.srcObject = remoteStream;

    // ë©”íƒ€ë°ì´í„° ë¡œë“œ í›„ ì¬ìƒ
    const onLoadedMetadata = () => {
      console.log("[CameraViewer] ğŸ“¹ Metadata loaded:", video.videoWidth, "x", video.videoHeight);
      attemptPlay(0);
    };

    // íŠ¸ë™ ì¶”ê°€ ì´ë²¤íŠ¸ ê°ì§€ - ëŠ¦ê²Œ ë„ì°©í•˜ëŠ” íŠ¸ë™ ì²˜ë¦¬
    const onAddTrack = () => {
      console.log("[CameraViewer] ğŸ“¹ Track added to stream, retrying play...");
      attemptPlay(0);
    };

    video.addEventListener("loadedmetadata", onLoadedMetadata);
    remoteStream.addEventListener("addtrack", onAddTrack);

    // ì¦‰ì‹œ ì¬ìƒ ì‹œë„ (ë©”íƒ€ë°ì´í„°ê°€ ì´ë¯¸ ìˆì„ ìˆ˜ ìˆìŒ)
    attemptPlay(0);

    return () => {
      video.removeEventListener("loadedmetadata", onLoadedMetadata);
      remoteStream.removeEventListener("addtrack", onAddTrack);
      if (playRetryTimerRef.current) {
        clearTimeout(playRetryTimerRef.current);
        playRetryTimerRef.current = null;
      }
    };
  }, [remoteStream, attemptPlay]);

  // Stream ë¹„í™œì„±í™” ê°ì§€
  useEffect(() => {
    if (!remoteStream) return;

    const checkStreamHealth = () => {
      const videoTracks = remoteStream.getVideoTracks();
      if (videoTracks.length > 0 && videoTracks[0].readyState === "ended") {
        console.log("[CameraViewer] âš ï¸ Video track ended");
        setIsVideoPlaying(false);
      }
    };

    const interval = setInterval(checkStreamHealth, 5000);
    return () => clearInterval(interval);
  }, [remoteStream]);

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      if (playRetryTimerRef.current) {
        clearTimeout(playRetryTimerRef.current);
      }
    };
  }, []);

  const handleDownload = () => {
    if (!videoRef.current) return;
    const canvas = document.createElement("canvas");
    canvas.width = videoRef.current.videoWidth || 1280;
    canvas.height = videoRef.current.videoHeight || 720;
    const ctx = canvas.getContext("2d");
    if (ctx) {
      ctx.drawImage(videoRef.current, 0, 0);
      const link = document.createElement("a");
      link.href = canvas.toDataURL("image/jpeg", 0.9);
      link.download = `meercop-capture-${Date.now()}.jpg`;
      link.click();
    }
  };

  // ë…¹í™” ì‹œì‘
  const startRecording = useCallback(() => {
    if (!remoteStream || isRecording) return;

    // ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ íŠ¸ë™ í™•ì¸ ë° ê²°í•© ìŠ¤íŠ¸ë¦¼ ìƒì„±
    const videoTracks = remoteStream.getVideoTracks();
    const audioTracks = remoteStream.getAudioTracks();
    console.log("[CameraViewer] ğŸ¬ Recording start - Video tracks:", videoTracks.length, "Audio tracks:", audioTracks.length);
    
    audioTracks.forEach((t, i) => {
      console.log(`[CameraViewer] ğŸ”Š Audio track ${i}:`, { enabled: t.enabled, muted: t.muted, readyState: t.readyState });
    });

    // ìƒˆ MediaStreamì„ ë§Œë“¤ì–´ ëª¨ë“  íŠ¸ë™ì„ ëª…ì‹œì ìœ¼ë¡œ ì¶”ê°€
    const recordingStream = new MediaStream();
    videoTracks.forEach(t => recordingStream.addTrack(t));
    audioTracks.forEach(t => recordingStream.addTrack(t));

    recordedChunksRef.current = [];
    const mimeType = MediaRecorder.isTypeSupported("video/webm;codecs=vp9,opus")
      ? "video/webm;codecs=vp9,opus"
      : MediaRecorder.isTypeSupported("video/webm;codecs=vp8,opus")
        ? "video/webm;codecs=vp8,opus"
        : "video/webm";

    console.log("[CameraViewer] ğŸ¬ Using mimeType:", mimeType, "Recording stream tracks:", recordingStream.getTracks().length);

    try {
      const recorder = new MediaRecorder(recordingStream, { mimeType });
      recorder.ondataavailable = (e) => {
        if (e.data.size > 0) recordedChunksRef.current.push(e.data);
      };
      recorder.onstop = () => {
        const blob = new Blob(recordedChunksRef.current, { type: mimeType });
        const url = URL.createObjectURL(blob);
        const link = document.createElement("a");
        link.href = url;
        link.download = `meercop-recording-${Date.now()}.webm`;
        link.click();
        URL.revokeObjectURL(url);
        recordedChunksRef.current = [];
      };
      recorder.start(1000);
      mediaRecorderRef.current = recorder;
      setIsRecording(true);
      setRecordingDuration(0);

      recordingTimerRef.current = setInterval(() => {
        setRecordingDuration((d) => d + 1);
      }, 1000);
    } catch (err) {
      console.error("[CameraViewer] Recording failed:", err);
    }
  }, [remoteStream, isRecording]);

  // ë…¹í™” ì¤‘ì§€
  const stopRecording = useCallback(() => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== "inactive") {
      mediaRecorderRef.current.stop();
    }
    mediaRecorderRef.current = null;
    setIsRecording(false);
    setRecordingDuration(0);
    if (recordingTimerRef.current) {
      clearInterval(recordingTimerRef.current);
      recordingTimerRef.current = null;
    }
  }, []);

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ë…¹í™” ì •ë¦¬
  useEffect(() => {
    return () => {
      if (mediaRecorderRef.current && mediaRecorderRef.current.state !== "inactive") {
        mediaRecorderRef.current.stop();
      }
      if (recordingTimerRef.current) clearInterval(recordingTimerRef.current);
    };
  }, []);

  const formatDuration = (seconds: number) => {
    const m = Math.floor(seconds / 60).toString().padStart(2, "0");
    const s = (seconds % 60).toString().padStart(2, "0");
    return `${m}:${s}`;
  };

  // Not streaming yet
  if (!isStreaming) {
    return (
      <div className="flex-1 bg-black/50 rounded-xl mx-4 flex items-center justify-center aspect-video">
        <div className="text-center flex flex-col items-center gap-4">
          <Video className="w-12 h-12 text-white/50" />
          <p className="text-white/70 text-sm px-4">
            ì¹´ë©”ë¼ë¥¼ ì‹œì‘í•˜ë ¤ë©´ ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”
          </p>
        </div>
      </div>
    );
  }

  // Connecting
  if (isConnecting && !isConnected) {
    return (
      <div className="flex-1 bg-black/50 rounded-xl mx-4 flex items-center justify-center aspect-video">
        <div className="text-center flex flex-col items-center gap-4">
          <RefreshCw className="w-8 h-8 text-white/50 animate-spin" />
          <p className="text-white/70 text-sm">ì¹´ë©”ë¼ ì—°ê²° ì¤‘...</p>
          <p className="text-white/50 text-xs">ë…¸íŠ¸ë¶ì—ì„œ ì¹´ë©”ë¼ê°€ ì‹œì‘ë  ë•Œê¹Œì§€ ëŒ€ê¸° ì¤‘</p>
        </div>
      </div>
    );
  }

  // Error state
  if (error) {
    return (
      <div className="flex-1 bg-black/50 rounded-xl mx-4 flex items-center justify-center aspect-video">
        <div className="text-center flex flex-col items-center gap-4">
          <p className="text-white/70 text-sm">{error}</p>
          <button
            onClick={onRetry}
            className="px-4 py-2 bg-white/10 border border-white/20 rounded-lg flex items-center gap-2 text-white/70 text-sm hover:bg-white/20 transition-colors"
          >
            <RefreshCw className="w-4 h-4" />
            ë‹¤ì‹œ ì‹œë„
          </button>
        </div>
      </div>
    );
  }

  // Connected with stream
  if (isConnected && remoteStream) {
    const handlePlayClick = () => {
      attemptPlay(0);
    };

    const handleToggleMute = () => {
      if (videoRef.current) {
        const newMuted = !videoRef.current.muted;
        videoRef.current.muted = newMuted;
        userMutePreferenceRef.current = newMuted;
        setIsMuted(newMuted);
      }
    };

    return (
      <div className="flex-1 bg-black rounded-xl mx-4 flex items-center justify-center relative overflow-hidden aspect-video">
        <video
          ref={videoRef}
          autoPlay
          playsInline
          muted
          preload="auto"
          className="w-full h-full object-contain"
          onClick={handlePlayClick}
        />

        {/* í„°ì¹˜í•˜ì—¬ ì¬ìƒ ì˜¤ë²„ë ˆì´ */}
        {!isVideoPlaying && (
          <div
            className="absolute inset-0 flex flex-col items-center justify-center bg-black/50 cursor-pointer"
            onClick={handlePlayClick}
          >
            <div className="w-16 h-16 rounded-full bg-white/20 flex items-center justify-center mb-2">
              <Play className="w-8 h-8 text-white ml-1" fill="white" />
            </div>
            <p className="text-white text-sm">í„°ì¹˜í•˜ì—¬ ì¬ìƒ</p>
          </div>
        )}

        {/* LIVE / REC indicator */}
        <div className="absolute top-3 right-3 flex items-center gap-1.5 bg-black/60 px-2 py-1 rounded">
          {isRecording ? (
            <>
              <div className="w-2 h-2 rounded-full bg-red-500 animate-pulse" />
              <span className="text-white text-xs font-bold">REC {formatDuration(recordingDuration)}</span>
            </>
          ) : (
            <>
              <div className="w-2 h-2 rounded-full bg-destructive animate-pulse" />
              <span className="text-white text-xs font-bold">LIVE</span>
            </>
          )}
        </div>
        {/* ì˜¤ë””ì˜¤ ë ˆë²¨ ì¸ë””ì¼€ì´í„° */}
        <div className="absolute top-3 left-3 flex items-center gap-1.5 bg-black/60 px-2 py-1.5 rounded">
          {hasAudioTrack ? (
            <>
              <Mic className="w-3 h-3 text-green-400" />
              <div className="flex items-end gap-[2px] h-3">
                {[0.15, 0.3, 0.45, 0.6, 0.75].map((threshold, i) => (
                  <div
                    key={i}
                    className="w-[3px] rounded-sm transition-all duration-100"
                    style={{
                      height: `${4 + i * 2}px`,
                      backgroundColor: audioLevel >= threshold 
                        ? audioLevel > 0.5 ? '#f59e0b' : '#4ade80' 
                        : 'rgba(255,255,255,0.2)',
                    }}
                  />
                ))}
              </div>
            </>
          ) : (
            <>
              <MicOff className="w-3 h-3 text-white/40" />
              <span className="text-white/40 text-[10px]">No Audio</span>
            </>
          )}
        </div>
        {/* Action buttons */}
        <div className="absolute bottom-3 right-3 flex gap-2">
          <button
            onClick={handleToggleMute}
            className={`w-10 h-10 rounded-full flex items-center justify-center text-white transition-colors ${
              isMuted ? "bg-white/20 hover:bg-white/30" : "bg-accent/80 hover:bg-accent"
            }`}
            title={isMuted ? "ì†Œë¦¬ ì¼œê¸°" : "ì†Œë¦¬ ë„ê¸°"}
          >
            {isMuted ? <VolumeX className="w-5 h-5" /> : <Volume2 className="w-5 h-5" />}
          </button>
          {/* ë…¹í™” ë²„íŠ¼ */}
          <button
            onClick={isRecording ? stopRecording : startRecording}
            className={`w-10 h-10 rounded-full flex items-center justify-center text-white transition-colors ${
              isRecording ? "bg-red-600 hover:bg-red-700" : "bg-white/20 hover:bg-white/30"
            }`}
            title={isRecording ? "ë…¹í™” ì¤‘ì§€" : "ë…¹í™” ì‹œì‘"}
          >
            {isRecording ? <Square className="w-4 h-4" fill="white" /> : <Circle className="w-5 h-5 text-red-400" />}
          </button>
          <button
            onClick={onCapture}
            className="w-10 h-10 bg-white/20 rounded-full flex items-center justify-center text-white hover:bg-white/30 transition-colors"
            title="ìŠ¤ëƒ…ìƒ· ì €ì¥"
          >
            <Camera className="w-5 h-5" />
          </button>
          <button
            onClick={handleDownload}
            className="w-10 h-10 bg-white/20 rounded-full flex items-center justify-center text-white hover:bg-white/30 transition-colors"
            title="ë‹¤ìš´ë¡œë“œ"
          >
            <Download className="w-5 h-5" />
          </button>
        </div>
      </div>
    );
  }

  // Waiting for connection
  return (
    <div className="flex-1 bg-black/50 rounded-xl mx-4 flex items-center justify-center aspect-video">
      <div className="text-center flex flex-col items-center gap-4">
        <RefreshCw className="w-6 h-6 text-white/50 animate-spin" />
        <p className="text-white/70 text-sm">ë…¸íŠ¸ë¶ì—ì„œ ì¹´ë©”ë¼ ì‹œì‘ ëŒ€ê¸° ì¤‘...</p>
        <p className="text-white/50 text-xs">ë…¸íŠ¸ë¶ ì•±ì´ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”</p>
      </div>
    </div>
  );
};

export default CameraViewer;
